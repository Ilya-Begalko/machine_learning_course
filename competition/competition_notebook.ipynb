{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Вступление\nЦель - создать набор данных и простую (1 скрытый слой) сеть для целей классификации. Я хочу, чтобы все было как можно более замкнутым. Возможно, есть более гибкие конструкции, но я сосредоточен только на решении классификатора цифр MNIST.\n\nПрежде всего, полезный импорт.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch.nn.functional as F","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## 1. Создайем загрузчики данных\nСамым сложным здесь было получение правильных форм и типов. Есть 2 объекта: один для обучающего набора (который возвращает данные и истинную метку) и один для тестового набора (который возвращает только данные).\nПоскольку в этой простой модели нас не интересует форма, данные возвращаются в виде вектора длиной 784.","metadata":{}},{"cell_type":"code","source":"class KaggleMNIST(Dataset):\n    \"\"\"Пользовательский набор данных для использования с pytorch.\n     Даже если у pytorch есть набор данных MNIST, для участия в Kaggle\n     конкуренция, нам лучше использовать набор данных Kaggle.\n     Этот класс загружает только набор данных поезда (изображения + метки).\n    \"\"\"\n    \n    def __init__(self, path):\n        data = np.loadtxt(path + 'train.csv', delimiter=',', skiprows=1, dtype=np.float32)\n        self._digits = torch.from_numpy(data[:, 1:]) / 255\n        self._labels = torch.from_numpy(data[:, 0]).type(torch.long)\n        self._size = len(data)\n        print('Training dataset with MNIST digits loaded.')\n        print('  Digits has shape:', self._digits.shape)\n        print('  Labels has shape:', self._labels.shape)\n        \n    def __getitem__(self, idx):\n        return (self._digits[idx], self._labels[idx])\n    \n    def __len__(self):\n        return self._size\n    \nclass KaggleMNIST_test(Dataset):\n    \"\"\"Пользовательский набор данных для использования с pytorch.\n     Даже если у pytorch есть набор данных MNIST, для участия в Kaggle\n     конкуренция, нам лучше использовать набор данных Kaggle.\n     Этот класс загружает только тестовый набор данных (изображения).\n    \"\"\"\n    \n    def __init__(self, path):\n        data = np.loadtxt(path + 'test.csv', delimiter=',', skiprows=1, dtype=np.float32)\n        self._digits = torch.from_numpy(data) / 256\n        self._size = len(data)\n        print('Testing dataset with MNIST digits loaded.')\n        print('  Digits has shape:', self._digits.shape)\n        \n    def __getitem__(self, idx):\n        return self._digits[idx]\n    \n    def __len__(self):\n        return self._size","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## 2. Вспомогательная функция\nЦель этой функции - уменьшить беспорядок.","metadata":{}},{"cell_type":"code","source":"def create_samplers(size, train_prop):\n    \"\"\"Функция, которая создает 2 подмножества из набора обучающих данных, одно из которых\n     используйте din-обучение, а другое - для проверки.\n    \n     Параметры\n     ----------\n     размер: числовой, целочисленный.\n         Количество элементов в наборе данных, которые нужно разделить на набор поездов и\n         набор для проверки.\n     train_prop: Числовое, с плавающей запятой.\n         Число от 0 до 1, определяющее пропорцию элементов.\n         который будет включен в набор для проверки.\n\n     Return\n     -------\n     Кортеж с двумя объектами SubsetRandomSampler, первый из которых будет использоваться с\n     обучающий DataLoader, а второй - с проверкой DataLoader.\n    \"\"\"\n    cut_point = int(size * train_prop)\n    shuffled = np.random.permutation(size)\n    train_sampler = SubsetRandomSampler(shuffled[:cut_point])\n    validation_sampler = SubsetRandomSampler(shuffled[cut_point:])\n    return train_sampler, validation_sampler","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## 3. Модель\nДля этой задачи функцией потерь является кросс-энтропия, а оптимизация выполняется с помощью стохастического градиентного спуска. Скрытые слои имеют функцию активации LeakyReLU, но я не видел, чтобы она была лучше или хуже, чем простой ReLU. Использование signoid показало несколько худшие результаты. Больше ничего не пробовал.\nМодель принимает заряжающие, а точность встроена.\nПроверка - это частный метод, поскольку он используется во время обучения, а результаты (эволюция потерь и точности) выводятся на экран и возвращаются методом fit () в случае, если пользователь хочет что-то сделать.","metadata":{}},{"cell_type":"code","source":"class MLP_1_HL_Classification(nn.Module):\n    \"\"\"Простой многослойный перцептрон с одним скрытым слоем, использующий\n     LeakyReLU как функция активации и кросс-энтропия как функция потерь,\n     быть примененным к задачам классификации.\n     Первая попытка поместить все в объект, поэтому модель\n     самодостаточный. Не уверен, действительно ли это необходимо.\n    \"\"\"\n\n    def __init__(self, input_size, hidden_size, output_size):\n        super().__init__()\n        self._input_size = input_size\n        self._hidden_size = hidden_size\n        self._output_size = output_size\n        self.train_loader = None\n        self.validation_loader = None\n        self._optimizer_fn = torch.optim.SGD\n        self._loss_fn = F.cross_entropy\n        self._net = nn.Sequential(\n            nn.Linear(self._input_size, self._hidden_size),\n            nn.LeakyReLU(),\n            nn.Linear(self._hidden_size, self._output_size))\n        \n    def forward(self, batch):\n        return self._net(batch)\n    \n    def define_loaders(self, train, validation):\n        self.train_loader = train\n        self.validation_loader = validation\n            \n    def _accuracy(self, outputs, labels):\n        preds = torch.max(outputs, dim=1)[1]\n        return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n                \n    def _validation_with_batch(self, batch):\n        images, labels = batch \n        preds = self(images)\n        loss = self._loss_fn(preds, labels, reduction='sum')\n        acc = self._accuracy(preds, labels) * len(labels)\n        return {'loss': loss, 'accuracy': acc}\n        \n    def _evaluate(self):\n        with torch.no_grad():\n            outputs = [self._validation_with_batch(batch) for batch in self.validation_loader]\n        samples = len(self.validation_loader.sampler.indices)\n        batch_losses = [x['loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).sum() / samples\n        batch_accuracies = [x['accuracy'] for x in outputs]\n        epoch_accuracy = torch.stack(batch_accuracies).sum() / samples\n        return {'loss': epoch_loss.item(), 'accuracy': epoch_accuracy.item()}\n    \n    def fit(self, epochs, learning_rate):\n        print(f'Training the model for {epochs} epochs with learning rate {learning_rate}.')\n        optim = self._optimizer_fn(self.parameters(), learning_rate)\n        history = []\n        for epoch in range(epochs):\n            # Training Phase \n            for batch in self.train_loader:\n                images, labels = batch \n                loss = self._loss_fn(self(images), labels)\n                loss.backward()\n                optim.step()\n                optim.zero_grad()\n            # Оценка эпох с помощью набора данных проверки.\n            result = self._evaluate()\n            print(\"Epoch [{}], loss: {:.4f}, accuracy: {:.4f}\".format(epoch, result['loss'], result['accuracy']))\n            history.append(result)\n        return history  \n","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## 4. Загрузка данных","metadata":{}},{"cell_type":"code","source":"train_set = KaggleMNIST('../input/digit-recognizer/')\ntest_set = KaggleMNIST_test('../input/digit-recognizer/')","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Training dataset with MNIST digits loaded.\n  Digits has shape: torch.Size([42000, 784])\n  Labels has shape: torch.Size([42000])\nTesting dataset with MNIST digits loaded.\n  Digits has shape: torch.Size([28000, 784])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 5. Дальнейшая настройка","metadata":{}},{"cell_type":"code","source":"batch_size = 80\nhidden_layer = 500\n\ntrain_sampler, validation_sampler = create_samplers(len(train_set), 0.8)\n\nprint(f'Size of training set: {len(train_sampler.indices)}.')\nprint(f'Size of validation set: {len(validation_sampler.indices)}.')\n\ntrain_loader = DataLoader(train_set, batch_size, sampler = train_sampler)\nvalidation_loader = DataLoader(train_set, batch_size, sampler = validation_sampler)","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Size of training set: 33600.\nSize of validation set: 8400.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 6. Создайте модель и обучите ее\nУчитывая, что мы знаем набор данных, размеры входного и выходного слоев являются константами.\n\nМетод подгонки предназначен для последовательных вызовов, изменяющих эпохи и скорость обучения. Показанные здесь были найдены методом проб и ошибок. Эта сеть, кажется, имеет максимальную точность 97%, и большее количество эпох или больший скрытый слой не улучшают ее, по крайней мере, в моих попытках.","metadata":{}},{"cell_type":"code","source":"model = MLP_1_HL_Classification(784, hidden_layer, 10)\nmodel.define_loaders(train_loader, validation_loader)\n\nmodel.fit(3, 0.15)\nmodel.fit(3, 0.1)\nmodel.fit(5, 0.05)\nmodel.fit(4, 0.025)\nmodel.fit(4, 0.01)\nmodel.fit(4, 0.005)\n\nresult0 = model._evaluate()\nprint(result0)","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Training the model for 3 epochs with learning rate 0.15.\nEpoch [0], loss: 0.3052, accuracy: 0.9087\nEpoch [1], loss: 0.2314, accuracy: 0.9332\nEpoch [2], loss: 0.1859, accuracy: 0.9461\nTraining the model for 3 epochs with learning rate 0.1.\nEpoch [0], loss: 0.1622, accuracy: 0.9527\nEpoch [1], loss: 0.1485, accuracy: 0.9567\nEpoch [2], loss: 0.1362, accuracy: 0.9607\nTraining the model for 5 epochs with learning rate 0.05.\nEpoch [0], loss: 0.1306, accuracy: 0.9623\nEpoch [1], loss: 0.1279, accuracy: 0.9627\nEpoch [2], loss: 0.1213, accuracy: 0.9633\nEpoch [3], loss: 0.1181, accuracy: 0.9655\nEpoch [4], loss: 0.1167, accuracy: 0.9649\nTraining the model for 4 epochs with learning rate 0.025.\nEpoch [0], loss: 0.1131, accuracy: 0.9662\nEpoch [1], loss: 0.1115, accuracy: 0.9664\nEpoch [2], loss: 0.1118, accuracy: 0.9655\nEpoch [3], loss: 0.1099, accuracy: 0.9665\nTraining the model for 4 epochs with learning rate 0.01.\nEpoch [0], loss: 0.1086, accuracy: 0.9668\nEpoch [1], loss: 0.1078, accuracy: 0.9680\nEpoch [2], loss: 0.1079, accuracy: 0.9675\nEpoch [3], loss: 0.1070, accuracy: 0.9680\nTraining the model for 4 epochs with learning rate 0.005.\nEpoch [0], loss: 0.1070, accuracy: 0.9673\nEpoch [1], loss: 0.1067, accuracy: 0.9680\nEpoch [2], loss: 0.1068, accuracy: 0.9677\nEpoch [3], loss: 0.1062, accuracy: 0.9685\n{'loss': 0.10617251694202423, 'accuracy': 0.9684523940086365}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 7. Конец","metadata":{}},{"cell_type":"code","source":"predictions = [[idx+1, torch.max(model(point), dim=1)[1].item()] for idx, point in enumerate(DataLoader(test_set))]\nsubmission = pd.DataFrame(predictions, columns=['ImageId', 'Label'])\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":17,"outputs":[]}]}